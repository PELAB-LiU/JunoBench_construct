{
  "executed": [
    {
      "execution_count": 1,
      "code_cell_id": 0,
      "code": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport plotly.express as px\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n for filename in filenames:\n print(os.path.join(dirname, filename))"
    },
    {
      "execution_count": 2,
      "code_cell_id": 10,
      "code": "from transformers import AutoTokenizer\n\ndf = pd.read_csv('data/train.csv')\n\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n\ndf.drop_duplicates(inplace=True)\ndf.dropna(subset=['output', 'instruction'], inplace=True)\n\ndf['instruction_tokens'] = df['instruction'].apply(lambda x: len(tokenizer.tokenize(x)))\ndf['output_tokens'] = df['output'].apply(lambda x: len(tokenizer.tokenize(x)))\n\nprint(df.head())"
    }
  ],
  "target": {
    "code_cell_id": 13,
    "code": "import pandas as pd\nimport torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\n\nmodel_name = \"gpt2\"\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\n\ngenerated_responses = []\n\nfor index, row in df.iterrows():\n prompt = row['instruction']\n input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n\n with torch.no_grad():\n output = model.generate(\n input_ids,\n max_length=input_ids.size(1) + 50,\n num_return_sequences=1,\n pad_token_id=tokenizer.eos_token_id,\n attention_mask=input_ids.ne(tokenizer.pad_token_id)\n )\n\n padded_output = output[:, input_ids.size(1):]\n\n response = tokenizer.decode(padded_output[0], skip_special_tokens=True)\n generated_responses.append(response)"
  }
}