{
  "executed": [
    {
      "execution_count": 1,
      "code_cell_id": 0,
      "code": "import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nimport time\nfrom skimage.io import imshow\nfrom IPython.display import display\nfrom skimage.transform import resize\nfrom tensorflow.keras.layers import Dense, BatchNormalization, LeakyReLU, Reshape\nfrom tensorflow.keras.layers import Conv2DTranspose, Input, Concatenate, Conv2D\nfrom tensorflow.keras.layers import Conv2D, Dropout, Flatten\nfrom tensorflow.keras.models import Model\nimport os\nimport glob\nfrom tensorflow.keras.callbacks import LambdaCallback"
    },
    {
      "execution_count": 2,
      "code_cell_id": 1,
      "code": "def Load_Pprepr_Data():\n Data = tf.keras.datasets.cifar10.load_data()\n (train_images , train_labels) , (test_images , test_labels) = Data\n return train_images ,train_labels ,test_images ,test_labels\n\ndef create_train_dataset(train_images, train_labels, batch_size):\n \"\"\"\n Creates a TensorFlow dataset for training the AC-GAN model.\n\n Args:\n train_images (ndarray): Array of training images.\n train_labels (ndarray): Array of training labels.\n batch_size (int): Number of samples per batch.\n\n Returns:\n tf.data.Dataset: Training dataset.\n \"\"\"\n\n BUFFER_SIZE = train_images.shape[0]\n\n train_dataset_y = tf.data.Dataset.from_tensor_slices(train_labels[:, 0]).map(lambda y: tf.one_hot(y, 10))\n\n train_dataset_x = tf.data.Dataset.from_tensor_slices(train_images)\n\n train_dataset = tf.data.Dataset.zip((train_dataset_x, train_dataset_y)).shuffle(BUFFER_SIZE).batch(batch_size)\n\n return train_dataset\n\ndef scale_image_to_float(image):\n \"\"\"\n Scales the pixel values of an image to the range [-1, 1].\n\n Args:\n image (numpy.ndarray): Input image.\n\n Returns:\n numpy.ndarray: Image with pixel values scaled to the range [-1, 1].\n \"\"\"\n return (image.astype(np.float32) - 127.5) / 127.5\n\ndef scale_image_to_uint8(image):\n \"\"\"\n Scales the pixel values of an image to the range [0, 255] and converts them to uint8.\n\n Args:\n image (numpy.ndarray): Input image.\n\n Returns:\n numpy.ndarray: Image with pixel values scaled to the range [0, 255] and converted to uint8.\n \"\"\"\n return np.clip((image * 127.5) + 128, 0, 255).astype(np.uint8)"
    },
    {
      "execution_count": 17,
      "code_cell_id": 3,
      "code": "class AC_GAN:\n\n def __init__(self):\n self.generator = None\n self.discriminator = None\n self.generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n self.discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n self.generator_gradients = None\n self.discriminator_gradients = None\n\n self.checkpoint_dir = './checkpoints'\n os.makedirs(self.checkpoint_dir, exist_ok=True)\n self.checkpoint_prefix = os.path.join(self.checkpoint_dir, 'ckpt')\n\n def build_generator(self,latent_dim, num_classes):\n \"\"\"\n Builds the AC-GAN generator model.\n\n Args:\n latent_dim (int): Dimension of the noise input.\n num_classes (int): Number of classes/labels.\n\n Returns:\n generator (Model): The AC-GAN generator model.\n \"\"\"\n\n noise_input = Input((latent_dim,))\n label_input = Input((num_classes,))\n\n x = Concatenate()([noise_input, label_input])\n\n x = Dense(4 * 4 * 256, use_bias=False)(x)\n x = BatchNormalization()(x)\n x = LeakyReLU()(x)\n\n x = Reshape((4, 4, 256))(x)\n\n x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n x = BatchNormalization()(x)\n x = LeakyReLU()(x)\n\n x = Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n x = BatchNormalization()(x)\n x = LeakyReLU()(x)\n\n x = Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n x = BatchNormalization()(x)\n x = LeakyReLU()(x)\n\n output = Conv2D(3, (3, 3), strides=(1, 1), padding='same', activation='tanh')(x)\n\n generator = Model(inputs=[noise_input, label_input], outputs=output)\n\n return generator\n\n def build_discriminator(self,input_shape):\n \"\"\"\n Build a discriminator model with the given input shape.\n\n Parameters:\n input_shape (tuple): Shape of the input images (height, width, channels).\n\n Returns:\n discriminator (Model): Discriminator model.\n\n \"\"\"\n _i = Input(input_shape)\n _ = Conv2D(64, (3, 3), strides=(2, 2), padding='same')(_i)\n _ = LeakyReLU()(_)\n _ = Conv2D(128, (3, 3), strides=(2, 2), padding='same', use_bias=False)(_)\n _ = BatchNormalization()(_)\n _ = LeakyReLU()(_)\n _ = Conv2D(128, (3, 3), strides=(2, 2), padding='same', use_bias=False)(_)\n _ = BatchNormalization()(_)\n _ = LeakyReLU()(_)\n _ = Conv2D(128, (3, 3), strides=(2, 2), padding='same', use_bias=False)(_)\n _ = BatchNormalization()(_)\n _ = LeakyReLU()(_)\n _ = Flatten()(_)\n _0 = Dense(1)(_)\n _1 = Dense(10)(_)\n\n discriminator = Model(inputs=_i, outputs=[_0, _1])\n return discriminator\n\n def prepare_generation(self,num_generated_examples, latent_dim):\n \"\"\"\n Prepare vectors for image generation.\n\n Args:\n num_epochs (int): Number of training epochs.\n num_generated_examples (int): Number of images to generate.\n latent_dim (int): Dimension of the latent space vector.\n\n Returns:\n random_vector_for_generation (tf.Tensor): Random vector for generating images.\n condition_vector_generation (tf.Tensor): Condition vector for generating images.\n \"\"\"\n\n random_vector_for_generation = tf.random.normal([num_generated_examples, latent_dim])\n condition_vector_generation = tf.one_hot(list(range(10)) * 2, 10)\n\n return random_vector_for_generation, condition_vector_generation\n\n def compute_compute_generator_loss(self,generated_output, labels):\n \"\"\"\n Computes the generator loss for adversarial and class label matching.\n\n Args:\n generated_output (tuple): Tuple containing the discriminator output and class predictions.\n labels (tf.Tensor): True class labels.\n\n Returns:\n tf.Tensor: Total generator loss.\n\n \"\"\"\n out_d, out_c = generated_output\n\n loss_discrit = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n labels=tf.ones_like(out_d), logits=out_d))\n\n loss_create = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n labels=labels, logits=out_c))\n\n whole_loss = loss_discrit + loss_create\n return whole_loss\n\n def compute_compute_discriminator_loss(self,real_discriminator_output, generated_discriminator_output, true_labels):\n \"\"\"\n Computes the discriminator loss for real and generated examples.\n\n Args:\n real_discriminator_output (tuple): Tuple containing the discriminator output and class predictions for real examples.\n generated_discriminator_output (tuple): Tuple containing the discriminator output and class predictions for generated examples.\n true_labels (tf.Tensor): True class labels.\n\n Returns:\n tf.Tensor: Total discriminator loss.\n\n \"\"\"\n real_output_d, real_output_c = real_discriminator_output\n\n real_loss_d = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n labels=tf.ones_like(real_output_d), logits=real_output_d))\n real_loss_c = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n labels=true_labels, logits=real_output_c))\n modified_real_loss = real_loss_d + real_loss_c\n\n generated_output_d, generated_output_c = generated_discriminator_output\n\n modified_generated_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n labels=tf.zeros_like(generated_output_d), logits=generated_output_d))\n\n modified_total_loss = modified_real_loss + modified_generated_loss\n\n return modified_total_loss\n\n def train_model(self,input_images, input_labels,latent_dim,BATCH_SIZE):\n \"\"\"\n Performs a single training step for the generator and discriminator models.\n\n Args:\n input_images (tf.Tensor): Batch of real images.\n input_labels (tf.Tensor): Batch of labels for the images.\n\n Returns:\n None\n \"\"\"\n\n noise = tf.random.normal([BATCH_SIZE, latent_dim])\n\n with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n\n generated_images = self.generator([noise, input_labels], training=True)\n\n real_outputs = self.discriminator(input_images, training=True)\n generated_outputs = self.discriminator(generated_images, training=True)\n\n generator_loss = self.compute_compute_generator_loss(generated_outputs, input_labels)\n discriminator_loss = self.compute_compute_discriminator_loss(real_outputs, generated_outputs, input_labels)\n\n self.generator_gradients = gen_tape.gradient(generator_loss, self.generator.trainable_variables)\n self.discriminator_gradients = disc_tape.gradient(discriminator_loss,self.discriminator.trainable_variables)\n\n self.generator_optimizer.apply_gradients(zip(self.generator_gradients, self.generator.trainable_variables))\n self.discriminator_optimizer.apply_gradients(zip(self.discriminator_gradients, self.discriminator.trainable_variables))\n\n def plot_images(self,images,epoch):\n\n np.save(\"all_images.npy\", np.array(images))\n print(f' generated images of epoch {epoch} , saved to all_images.npy')\n\n fig, axes = plt.subplots(nrows=2, ncols=10, figsize=(40, 20))\n\n axes = axes.flatten()\n\n for i in range(20):\n axes[i].imshow(images[i])\n axes[i].axis('off')\n\n fig.suptitle(f'Generated images of epoch :{epoch}', fontsize=42)\n\n plt.tight_layout()\n\n plt.show()\n\n def save_weights(self, checkpoint_name):\n\n old_weights = glob.glob(f\"{self.checkpoint_prefix}*\")\n for weight_file in old_weights:\n os.remove(weight_file)\n\n self.generator.save_weights(f\"{self.checkpoint_prefix}_generator_{checkpoint_name}.weights.h5\")\n self.discriminator.save_weights(f\"{self.checkpoint_prefix}_discriminator_{checkpoint_name}.weights.h5\")\n\n def train(self, train_dataset, latent_dim, num_class, num_examples_to_generate, epochs, batch_size=25):\n self.generator = self.build_generator(latent_dim, num_class)\n self.discriminator = self.build_discriminator((32, 32, 3))\n\n random_vector_for_generation, condition_vector_generation = self.prepare_generation(num_examples_to_generate,\n latent_dim)\n generated = []\n\n for epoch in range(epochs):\n\n start_time = time.time()\n\n for images, labels in train_dataset:\n\n self.train_model(images, labels, latent_dim, batch_size)\n\n noise = tf.random.normal([num_examples_to_generate, latent_dim])\n\n generated_image = self.generator([noise, condition_vector_generation], training=False)\n print(np.array(generated_image).shape)\n\n self.plot_images(generated_image, epoch)\n generated.append(generated_image)\n\n print(epoch, time.time() - start_time)\n\n self.save_weights(f\"epoch_{epoch}\")\n\n return np.array(generated)"
    },
    {
      "execution_count": 18,
      "code_cell_id": 4,
      "code": "train_images ,train_labels ,test_images ,test_labels = Load_Pprepr_Data()\ntrain_img_f32 = scale_image_to_float(train_images)\ntrain_dataset = create_train_dataset(train_img_f32, train_labels, 25)"
    },
    {
      "execution_count": 19,
      "code_cell_id": 5,
      "code": "train_dataset_small = train_dataset.take(16)\n\nprint('start')\nacgn = AC_GAN()\n\ncheckpoint_dir = 'checkpoints'\n\ngenerator_weights_file = os.path.join(checkpoint_dir, 'ckpt_generator_epoch_2')\ndiscriminator_weights_file = os.path.join(checkpoint_dir, 'ckpt_discriminator_epoch_2')\n\ngenerator_files_exist = os.path.exists(generator_weights_file + '.data-00000-of-00001') and os.path.exists(generator_weights_file + '.index')\ndiscriminator_files_exist = os.path.exists(discriminator_weights_file + '.data-00000-of-00001') and os.path.exists(discriminator_weights_file + '.index')\n\nprint(generator_files_exist)\nprint(discriminator_files_exist)\nif(generator_files_exist and discriminator_files_exist):\n acgn.generator = acgn.build_generator(100, 10)\n acgn.discriminator = acgn.build_discriminator((32, 32, 3))\n acgn.generator.load_weights(generator_weights_file)\n acgn.discriminator.load_weights(discriminator_weights_file)\n images = acgn.train(train_dataset_small,100,10,20,1,25)\nelse:\n print('no wieght found')\n images = acgn.train(train_dataset_small,100,10,20,1,25)"
    }
  ],
  "target": {
    "code_cell_id": 6,
    "code": "np.savetxt('images.txt', images, delimiter=',', fmt='%d')"
  }
}