{
  "executed": [
    {
      "execution_count": 1,
      "code_cell_id": 1,
      "code": "import json\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom IPython.display import clear_output\nfrom qiskit import QuantumCircuit\nfrom qiskit.circuit import ParameterVector\nfrom qiskit.circuit.library import ZFeatureMap\nfrom qiskit.quantum_info import SparsePauliOp\nfrom qiskit_algorithms.optimizers import COBYLA\nfrom qiskit_algorithms.utils import algorithm_globals\nfrom qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\nfrom qiskit_machine_learning.neural_networks import EstimatorQNN\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pyarrow.parquet as pq\nimport pandas as pd\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom torch import Tensor\nfrom torch.nn import Linear, CrossEntropyLoss, MSELoss\nfrom torch.optim import LBFGS\n\nfrom qiskit import QuantumCircuit\nfrom qiskit.circuit import Parameter\nfrom qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\nfrom qiskit_algorithms.utils import algorithm_globals\nfrom qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\nfrom qiskit_machine_learning.connectors import TorchConnector\n\nalgorithm_globals.random_seed = 42\n\nimport torch\nfrom torch import cat, no_grad, manual_seed\nfrom torch.utils.data import DataLoader,Dataset\nfrom torchvision import datasets, transforms\nimport torch.optim as optim\nfrom torch.nn import (\n Module,\n Conv2d,\n Linear,\n Dropout2d,\n NLLLoss,\n MaxPool2d,\n Flatten,\n Sequential,\n ReLU,\n)\nimport torch.nn.functional as F"
    },
    {
      "execution_count": 2,
      "code_cell_id": 2,
      "code": "import numpy as np\nimport pandas as pd\nimport pyarrow.parquet as pq\nimport matplotlib.pyplot as plt\n\ndef to_3d(arr):\n douaa = []\n for i in range(0, 3):\n dou = np.stack(np.stack(arr)[i], axis=-1)\n douaa.append(dou)\n douaa = np.array(douaa)\n return douaa\n\nparquet_file_path = 'data/QCDToGGQQ_IMGjet_RH1all_jet0_run0_n36272.test.snappy.parquet'\nparquet_file = pq.ParquetFile(parquet_file_path)\n\ntotal_rows = parquet_file.metadata.num_rows\n\nimages_array = []\nlabels_array = []\n\nchunk_size = 50\nfor i in range(0, total_rows, chunk_size):\n\n chunk = parquet_file.read_row_group(i)\n df = chunk.to_pandas()\n\n chunk_images_array = []\n chunk_labels_array = []\n\n for j in range(len(df)):\n\n df['X_jets'][j] = to_3d(df['X_jets'][j].copy())\n\n chunk_images_array.append(df['X_jets'][j])\n chunk_labels_array.append(df['y'][j])\n\n images_array.extend(chunk_images_array)\n labels_array.extend(chunk_labels_array)\n\nimages_array = np.array(images_array)\nlabels_array = np.array(labels_array)"
    },
    {
      "execution_count": 3,
      "code_cell_id": 3,
      "code": "train_images, test_images, train_labels, test_labels = train_test_split(\n images_array, labels_array, test_size=0.3\n)\n\nprint(train_images.shape)\nprint(train_labels.shape)"
    },
    {
      "execution_count": 4,
      "code_cell_id": 4,
      "code": "import numpy as np\nimport matplotlib.pyplot as plt\n\nreduced_images_array = np.mean(train_images, axis=1)\n\nnum_images_to_plot = 1\nfor i in range(num_images_to_plot):\n plt.imshow(reduced_images_array[i], cmap='gray')\n plt.title(f\"Label: {labels_array[i]}\")\n plt.show()"
    },
    {
      "execution_count": 5,
      "code_cell_id": 5,
      "code": "import numpy as np\nfrom scipy.ndimage import zoom\n\ntarget_shape = (125, 125)\n\nresized_images = np.zeros((reduced_images_array.shape[0], *target_shape))\n\nfor i in range(reduced_images_array.shape[0]):\n resized_images[i] = zoom(reduced_images_array[i], (target_shape[0] / reduced_images_array.shape[1], target_shape[1] / reduced_images_array.shape[2]))\n\nprint(resized_images.shape)"
    },
    {
      "execution_count": 6,
      "code_cell_id": 6,
      "code": "import torch\n\nimport torch\nfrom torchvision import transforms\n\nresized_images = resized_images.astype(np.float32)\ntrain_labels = train_labels.astype(np.float32)\n\ntransform = transforms.Compose([\n transforms.ToTensor(),\n])\n\ntensor_images = torch.stack([transform(img) for img in resized_images])\n\nlabel_transform = transforms.Compose([\n transforms.Lambda(lambda x: torch.tensor(x, dtype=torch.float32)),\n])\n\ntensor_labels = label_transform(train_labels).long()\n\nclass CustomDataset(Dataset):\n def __init__(self, images, labels):\n self.images = images\n self.labels = labels\n\n def __len__(self):\n return len(self.images)\n\n def __getitem__(self, idx):\n return self.images[idx], self.labels[idx]\n\nbatch_size = 1\nshuffle = True\n\ncustom_dataset = CustomDataset(tensor_images, tensor_labels)\ntrain_loader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=shuffle)"
    },
    {
      "execution_count": 7,
      "code_cell_id": 7,
      "code": "print(custom_dataset.images.shape)\nprint(custom_dataset.labels.shape)"
    }
  ],
  "target": {
    "code_cell_id": 8,
    "code": "plt.imshow(custom_dataset.images[1][0, :, :])\nplt.imshow(custom_dataset.labels[0])\n\nplt.title(f\"Label: {labels_array[1]}\")\nplt.show()"
  }
}