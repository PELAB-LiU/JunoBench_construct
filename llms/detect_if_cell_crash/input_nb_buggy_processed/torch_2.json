{
  "executed": [
    {
      "execution_count": 1,
      "code_cell_id": 0,
      "code": "from torchvision.io import read_image\nfrom torchvision.models import vit_b_16, ViT_B_16_Weights, list_models\nfrom torchvision.datasets import ImageNet, ImageFolder\nfrom torch.utils.data import DataLoader\nfrom torchmetrics.classification import MulticlassAccuracy\nimport torch\nimport time\nfrom torchvision.transforms import transforms"
    },
    {
      "execution_count": 6,
      "code_cell_id": 1,
      "code": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device used is: \" + str(device))\n\nmetric = MulticlassAccuracy(num_classes=1000).to(device)\n\npreprocess = weights.transforms(antialias=True)\n\npreprocess_w_gray2rgb = transforms.Compose([\n lambda x: x.expand(3, -1, -1) if x.shape[0] == 1 else x,\n preprocess\n])\nimagenet_val_dir = 'data_small'\ndataset = ImageFolder(root=imagenet_val_dir, loader=read_image, transform=preprocess_w_gray2rgb)\nclass_dict = dataset.class_to_idx\nclass_dict = {value: key for key, value in class_dict.items()}\n\ndataloader = DataLoader(dataset, batch_size=8, shuffle=False)"
    },
    {
      "execution_count": 5,
      "code_cell_id": 2,
      "code": "img = read_image(\"data_small/10/ILSVRC2012_val_00037698.jpeg\")\nprint(img.shape[0])\nif img.shape[0] == 1:\n img = img.expand(3, -1, -1)\nprint(img.size())\n\nweights =ViT_B_16_Weights.IMAGENET1K_SWAG_E2E_V1\nmodel = vit_b_16(weights=weights)\nmodel.eval()\n\npreprocess = weights.transforms()\n\nbatch = preprocess(img).unsqueeze(0)\n\nprediction = model(batch).squeeze(0).softmax(0)\nclass_id = prediction.argmax().item()\nprint(class_id)\nscore = prediction[class_id].item()\ncategory_name = weights.meta[\"categories\"][class_id]\nprint(f\"{category_name}: {100 * score:.1f}%\")"
    },
    {
      "execution_count": 7,
      "code_cell_id": 3,
      "code": "def check_label_name(predictions, weights):\n for prediction in predictions:\n class_id = prediction.argmax().item()\n print(class_id)\n score = prediction[class_id].item()\n category_name = weights.meta[\"categories\"][class_id]\n print(f\"{category_name}: {100 * score:.1f}%\")\n print(\"\\n\")\n\ndef model_quantization(model, backend='x86', save=False):\n\n model.qconfig = torch.quantization.get_default_qconfig(backend)\n torch.backends.quantized.engine = backend\n\n quantized_model = torch.quantization.quantize_dynamic(model, qconfig_spec={torch.nn.Linear}, dtype=torch.qint8)\n scripted_quantized_model = torch.jit.script(quantized_model)\n if save:\n scripted_quantized_model.save(\"vit_scripted_quantized.pt\")\n\ndef labels_process(labels, class_dict):\n\n labels = [class_dict[int(label)] for label in labels]\n labels = [int(num) for num in labels]\n labels = torch.tensor(labels)\n return labels\n\ndef inference(model, dataloader, class_dict, device, image_num_stop=40000):\n index_stop = image_num_stop // 8\n total_correct = 0\n total_samples = 0\n start_time = time.time()\n model.to(device)\n model.eval()\n\n with torch.no_grad():\n for index, (images, labels) in enumerate(dataloader):\n images = images.to(device)\n\n labels = labels_process(labels, class_dict)\n labels = labels.to(device)\n\n predictions = model(images)\n predicted_labels = torch.argmax(predictions, dim=1) + 1\n\n total_correct += (predicted_labels == labels).sum().item()\n total_samples += labels.size(0)\n\n if index % 50 == 0:\n print(\"{} images were processed out of 50,000\".format(8 * index))\n\n if index == index_stop:\n print(\"Number of images processed: {} stopping now\".format(index_stop*8))\n print(\"stopped checking because of errors for the entire dataset \\n \")\n break\n\n accuracy = total_correct / total_samples\n end_time = time.time()\n duration = (end_time - start_time) / 60\n\n return accuracy, duration"
    }
  ],
  "target": {
    "code_cell_id": 5,
    "code": "weights = ViT_B_16_Weights.IMAGENET1K_SWAG_E2E_V1\nmodel = vit_b_16(weights=weights)\nquantized_vit = model_quantization(model=model, save=True)\n\naccuracy, duration = inference(model=model, dataloader=dataloader, class_dict=class_dict, device=device, image_num_stop=100)\n\nprint(\"Inference took {} minutes\".format(duration))\nprint(\"Accuracy for this model is {}\".format(accuracy))"
  }
}