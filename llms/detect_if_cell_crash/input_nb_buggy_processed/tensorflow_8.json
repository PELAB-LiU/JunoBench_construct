{
  "executed": [
    {
      "execution_count": 1,
      "code_cell_id": 0,
      "code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nimport os\nfrom os import listdir\nfrom tqdm import tqdm\nimport shutil\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\n\nfrom keras.utils import to_categorical\nfrom keras.preprocessing import image\n\nfrom keras.layers import Input, Add, Activation, Dropout, Flatten, Dense, AveragePooling2D, MaxPooling2D, BatchNormalization, Conv2D, GlobalAveragePooling2D, Lambda,Permute,ZeroPadding2D,DepthwiseConv2D,Reshape,Concatenate\n\nfrom keras.callbacks import LearningRateScheduler\nfrom keras import backend as K\n\n%matplotlib inline"
    },
    {
      "execution_count": 2,
      "code_cell_id": 2,
      "code": "size=75"
    },
    {
      "execution_count": 3,
      "code_cell_id": 4,
      "code": "def getListOfFiles(dirName):\n listOfFile = os.listdir(dirName)\n allFiles = list()\n for entry in listOfFile:\n fullPath = os.path.join(dirName, entry)\n if os.path.isdir(fullPath):\n allFiles = allFiles + getListOfFiles(fullPath)\n else:\n allFiles.append(fullPath)\n\n return allFiles"
    },
    {
      "execution_count": 4,
      "code_cell_id": 6,
      "code": "benign_images = getListOfFiles('data/augmented/benign')\nmalignent_images = getListOfFiles('data/augmented/malignant')"
    },
    {
      "execution_count": 5,
      "code_cell_id": 9,
      "code": "total_images = len(benign_images) + len(malignent_images)\ntotal_images"
    },
    {
      "execution_count": 6,
      "code_cell_id": 10,
      "code": "data = pd.DataFrame(index=np.arange(0, len(benign_images)+len(malignent_images)), columns=[\"image\", \"target\"])\nk=0\n\nfor c in [0,1]:\n if c==1:\n for m in range(len(benign_images)):\n data.iloc[k][\"image\"] = benign_images[m]\n data.iloc[k][\"target\"] = 0\n k += 1\n else:\n for m in range(len(malignent_images)):\n data.iloc[k][\"image\"] = malignent_images[m]\n data.iloc[k][\"target\"] = 1\n k += 1"
    },
    {
      "execution_count": 7,
      "code_cell_id": 11,
      "code": "data.head(20)"
    },
    {
      "execution_count": 8,
      "code_cell_id": 12,
      "code": "data.shape"
    },
    {
      "execution_count": 9,
      "code_cell_id": 13,
      "code": "count_data = data[\"target\"].value_counts()\ncount_data"
    },
    {
      "execution_count": 10,
      "code_cell_id": 14,
      "code": "ben_upsampled = resample(data[data['target']==0],n_samples=data[data['target']==1].shape[0], random_state=42)\n\nup_sampled = pd.concat([data[data['target']==1], ben_upsampled])\n\nup_sampled['target'].value_counts()"
    },
    {
      "execution_count": 11,
      "code_cell_id": 15,
      "code": "ben_upsampled.head(10)"
    },
    {
      "execution_count": 12,
      "code_cell_id": 16,
      "code": "up_sampled.shape"
    },
    {
      "execution_count": 13,
      "code_cell_id": 17,
      "code": "train_image = []\ny = []\n\nfor i in tqdm(range(up_sampled.shape[0])):\n img = tf.keras.utils.load_img(up_sampled['image'].iloc[i], target_size=(size,size,1), color_mode=\"grayscale\")\n img = tf.keras.utils.img_to_array(img)\n img = img/255\n train_image.append(img)\n\nX = np.array(train_image)\ny = up_sampled.iloc[:,-1].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\nX_test, X_val, y_test, y_val = train_test_split(X_test, y_test, random_state=42, test_size=0.2 , shuffle=True)\n\nY_train = to_categorical(y_train, 2)\nY_test = to_categorical(y_test, 2)\nY_val = to_categorical(y_val, 2)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(X_val.shape)"
    },
    {
      "execution_count": 14,
      "code_cell_id": 18,
      "code": "def channel_shuffle(x, groups):\n \"\"\"\n Channel shuffle operation as described in the ShuffleNet paper.\n\n Args:\n x: Input tensor.\n groups: Number of groups to divide the channels into.\n\n Returns:\n Channel shuffled tensor.\n \"\"\"\n def shuffle_op(x):\n batch_size, height, width, channels = x.shape.as_list()\n channels_per_group = channels // groups\n x = tf.reshape(x, [-1, height, width, groups, channels_per_group])\n x = tf.transpose(x, [0, 1, 2, 4, 3])\n x = tf.reshape(x, [-1, height, width, channels])\n return x\n\n return Lambda(shuffle_op)(x)"
    },
    {
      "execution_count": 15,
      "code_cell_id": 19,
      "code": "def shuffle_unit(x, in_channels, out_channels, bottleneck_channels):\n\n res = x\n\n x = Conv2D(filters=bottleneck_channels, kernel_size=(1, 1), strides=(1, 1), padding='same', use_bias=False,groups=2)(x)\n x = BatchNormalization()(x)\n x = Activation('relu')(x)\n\n x = Lambda(channel_shuffle, arguments={'groups': 2})(x)\n\n x = DepthwiseConv2D(kernel_size=(1, 3), strides=(1, 1), padding='same', use_bias=False)(x)\n x = BatchNormalization()(x)\n\n x = DepthwiseConv2D(kernel_size=(3, 1), strides=(1, 1), padding='same', use_bias=False)(x)\n x = BatchNormalization()(x)\n\n x = Conv2D(filters=out_channels, kernel_size=(1, 1), strides=(1, 1), padding='same', use_bias=False,groups=2)(x)\n x = BatchNormalization()(x)\n x = Activation('relu')(x)\n\n if in_channels != out_channels:\n res = Conv2D(filters=out_channels, kernel_size=(1, 1), strides=(1, 1), padding='same', use_bias=False)(res)\n res = BatchNormalization()(res)\n\n x = Concatenate()([x, res])\n x = Activation('relu')(x)\n\n return x"
    },
    {
      "execution_count": 16,
      "code_cell_id": 20,
      "code": "def GridSizeReductionBlock(inputs, filters):\n\n path1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(inputs)\n\n path2 = Conv2D(filters=filters, kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu')(inputs)\n\n path3 = Conv2D(filters=filters//2, kernel_size=(1, 1), strides=(1, 1), padding='same', activation='relu')(inputs)\n path3 = Conv2D(filters=filters, kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu')(path3)\n\n output = Concatenate()([path1, path2, path3])\n return output"
    },
    {
      "execution_count": 18,
      "code_cell_id": 21,
      "code": "inputs = Input(shape=(size, size, 3))\n\nx = Conv2D(filters=64, kernel_size=(3, 3), strides=(2, 2), padding='same', use_bias=False)(inputs)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\n\nx = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n\nx = shuffle_unit(x, in_channels=64, out_channels=256, bottleneck_channels=64)\nx = shuffle_unit(x, in_channels=64, out_channels=256, bottleneck_channels=64)\nx = shuffle_unit(x, in_channels=64, out_channels=256, bottleneck_channels=64)\n\nx = GridSizeReductionBlock(x, filters=256)\n\nx = shuffle_unit(x, in_channels=128, out_channels=512, bottleneck_channels=128)\nx = shuffle_unit(x, in_channels=128, out_channels=512, bottleneck_channels=128)\nx = shuffle_unit(x, in_channels=128, out_channels=512, bottleneck_channels=128)\nx = shuffle_unit(x, in_channels=128, out_channels=512, bottleneck_channels=128)\nx = GridSizeReductionBlock(x, filters=512)\n\nx = shuffle_unit(x, in_channels=256, out_channels=1024, bottleneck_channels=256)\nx = shuffle_unit(x, in_channels=256, out_channels=1024, bottleneck_channels=256)\nx = shuffle_unit(x, in_channels=256, out_channels=1024, bottleneck_channels=256)\nx = shuffle_unit(x, in_channels=256, out_channels=1024, bottleneck_channels=256)\nx = shuffle_unit(x, in_channels=256, out_channels=1024, bottleneck_channels=256)\nx = shuffle_unit(x, in_channels=256, out_channels=1024, bottleneck_channels=256)\nx = GridSizeReductionBlock(x, filters=1024)\n\nx = shuffle_unit(x, in_channels=512, out_channels=2048, bottleneck_channels=512)\nx = shuffle_unit(x, in_channels=512, out_channels=2048, bottleneck_channels=512)\nx = shuffle_unit(x, in_channels=512, out_channels=2048, bottleneck_channels=512)\nx = GridSizeReductionBlock(x, filters=2048)\n\nx = GlobalAveragePooling2D()(x)\nx = Dense(units=2, activation='softmax')(x)\n\nmodel = Model(inputs=inputs, outputs=x)"
    }
  ],
  "target": {
    "code_cell_id": 31,
    "code": "y_pred = model.predict_classes(X_val)\nacc_test = 0\n\nfor i in range(X_val.shape[0]):\n if(y_pred[i] == y_val[i]):\n acc_test= acc_test+1\nprint(\"Accuracy test : \" , acc_test/X_val.shape[0]*100)"
  }
}