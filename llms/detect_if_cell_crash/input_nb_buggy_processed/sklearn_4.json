{
  "executed": [
    {
      "execution_count": 2,
      "code_cell_id": 0,
      "code": "import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n for filename in filenames:\n print(os.path.join(dirname, filename))"
    },
    {
      "execution_count": 3,
      "code_cell_id": 62,
      "code": "from sklearn.model_selection import ( train_test_split, KFold, StratifiedKFold,cross_val_score, RepeatedKFold, RandomizedSearchCV,learning_curve, ShuffleSplit, GridSearchCV)\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import (IterativeImputer, SimpleImputer, KNNImputer)\nfrom sklearn.preprocessing import PowerTransformer, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import (AdaBoostRegressor, RandomForestClassifier, RandomForestRegressor)\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import ( confusion_matrix , ConfusionMatrixDisplay, balanced_accuracy_score, roc_auc_score)\nimport plotly.graph_objects as go\nimport re\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom lightgbm import LGBMClassifier\nimport matplotlib.pylab as plt\nnp.seterr(divide = 'ignore')"
    },
    {
      "execution_count": 4,
      "code_cell_id": 63,
      "code": "class SelectColumnsTransformer():\n\n def __init__(self, columns=None):\n self.columns = columns\n\n def transform(self, X, **transform_params):\n cpy_df = X[self.columns].copy()\n return cpy_df\n\n def fit(self, X, y=None, **fit_params):\n return self"
    },
    {
      "execution_count": 5,
      "code_cell_id": 64,
      "code": "class DataframeFunctionTransformer():\n def __init__(self, func):\n self.func = func\n\n def transform(self, input_df, **transform_params):\n return self.func(input_df)\n\n def fit(self, X, y=None, **fit_params):\n return self"
    },
    {
      "execution_count": 7,
      "code_cell_id": 65,
      "code": "class ml_support():\n def __init__(self):\n self.df = pd.read_csv(\"data/credit_risk_dataset.csv\", encoding='latin')\n self.output_var = 'loan_status'\n self.num_cols = ['person_age','person_income','loan_amnt','loan_percent_income','cb_person_cred_hist_length']\n self.cat_cols = ['person_home_ownership','loan_intent','loan_grade','cb_person_default_on_file','higher_salary','home_owner','long_working','lower_loan_requirement','higher_loan_requirement']\n\n self.cols_wofeature = [col for col in self.df.columns if col != self.output_var ]\n\n self.cols_wfeature = ['person_age','person_income','loan_amnt','loan_percent_income','cb_person_cred_hist_length','person_home_ownership','loan_intent','loan_grade','cb_person_default_on_file','higher_salary','home_owner','long_working','lower_loan_requirement','higher_loan_requirement']\n self.X = self.df[self.cols_wofeature]\n\n self.y = self.df[self.output_var]\n self.random_state = 42\n\n def drop_duplicate(self):\n\n self.df.drop_duplicates(inplace=True)\n return self.df\n\n def get_train_test_data(self):\n\n X_train, X_test , y_train, y_test = train_test_split(self.X,self.y,test_size=0.2,\n random_state = self.random_state, shuffle=True, stratify=self.df[self.output_var])\n return X_train, X_test , y_train, y_test\n\n def get_column_transformer(self,is_estimator, iterative_Estimator, is_TreeBased=False):\n\n num_pipeline_steps = []\n iterative_imputer = IterativeImputer()\n if is_estimator:\n iterative_imputer = IterativeImputer(estimator=iterative_Estimator)\n\n num_pipeline_steps.append(('num_missing',iterative_imputer))\n\n if not is_TreeBased:\n num_pipeline_steps.append(('num_smoothening',PowerTransformer()))\n\n num_pipeline = Pipeline(num_pipeline_steps)\n\n cat_pipeline = Pipeline([\n ('cat_encoding',OneHotEncoder(sparse=False,drop='if_binary',handle_unknown='ignore'))\n ])\n\n ct = ColumnTransformer([\n ('num_munging',num_pipeline,self.num_cols),\n ('cat_munging',cat_pipeline,self.cat_cols)\n ])\n return ct\n\n def get_final_pipeline(self,regression_model,columntransformer, feature_engieered):\n\n X_train, X_test , y_train, y_test = self.get_train_test_data()\n features_pipeline = [feature_engieered]\n features_pipeline.append((\"selector\", SelectColumnsTransformer(self.cols_wfeature)))\n features_pipeline.append(('munging',columntransformer))\n features_pipeline.append(('model',regression_model))\n finalized_pipeline = Pipeline(features_pipeline)\n return finalized_pipeline;\n\n def predit_with_pipeline(self,pipeline,X_train,X_test,y_train):\n pipeline.fit(X_train,y_train)\n preds = pipeline.predict(X_test)\n return preds\n\n def get_best_params(self,pipeline,params):\n\n rscv = RandomizedSearchCV(pipeline, params, scoring='balanced_accuracy',\n n_jobs=-1, n_iter=4, cv=5, random_state=self.random_state, verbose=3)\n rscv.fit(self.X,self.y)\n return rscv.best_params_\n\n def get_best_params_gcv(self,pipeline,params):\n\n rscv = GridSearchCV(pipeline, params, scoring='balanced_accuracy',\n n_jobs=-1, cv=5, verbose=3)\n rscv.fit(self.X,self.y)\n return rscv.best_params_\n\n def plot_confusion_matrix(self,y_test, preds, finalized_pipeline):\n\n cm = confusion_matrix(y_test, preds, labels=finalized_pipeline.classes_)\n disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels= finalized_pipeline.classes_)\n disp.plot();\n plt.show();\n\n def update_performance_matrics(self,model_info,df):\n\n filter_con = df[\"Model_Name\"] == model_info['Model_Name']\n if ((filter_con)).any():\n df.loc[filter_con, 'Score'] = model_info['Score']\n else:\n df = df.append(model_info, ignore_index=True)\n return df\n\n def plot_learning_curves(self,estimator):\n \"\"\"\n Don't forget to change the scoring and plot labels\n based on the metric that you are using.\n \"\"\"\n train_sizes, train_scores, test_scores = learning_curve(\n estimator=estimator,\n X=self.X,\n y=self.y,\n train_sizes=np.linspace(0.1, 1.0, 5),\n cv=5,\n scoring=\"balanced_accuracy\",\n random_state=self.random_state,\n n_jobs=-1\n )\n train_mean = np.mean(train_scores, axis=1)\n test_mean = np.mean(test_scores, axis=1)\n fig = go.Figure()\n fig.add_trace(\n go.Scatter(\n x=train_sizes,\n y=train_mean,\n name=\"Training Accuracy\",\n mode=\"lines\",\n line=dict(color=\"blue\"),\n )\n )\n fig.add_trace(\n go.Scatter(\n x=train_sizes,\n y=test_mean,\n name=\"Validation Accuracy\",\n mode=\"lines\",\n line=dict(color=\"green\"),\n )\n )\n fig.update_layout(\n title=\"Learning Curves\",\n xaxis_title=\"Number of training examples\",\n yaxis_title=\"Balenced Accuracy\",\n )\n fig.show()"
    },
    {
      "execution_count": 8,
      "code_cell_id": 66,
      "code": "def get_higher_whisker(grp):\n try:\n q1, q3 = grp.quantile(0.25), grp.quantile(0.75)\n iqr = q3 - q1\n higher_whisker = q3 + (1.5*iqr)\n return higher_whisker\n except Exception as e:\n print(\"------------Error Occured-----------\")\n print(traceback.format_exc())\n\ndef impute_higher_salary(df):\n\n df[\"higher_whisker\"] = df.groupby('person_age')['person_income'].transform(lambda x: get_higher_whisker(x))\n df['higher_salary'] = df['person_income'] > df['higher_whisker']\n return df;\n\ndef define_home_owner(df):\n df['home_owner'] = df['person_home_ownership']=='OWN'\n return df\n\ndef define_loan_percentage(df):\n df['loan_percent_calc'] = (df['loan_amnt'] / df['person_income'])*100\n return df\n\ndef define_lower_loan_requirement(df):\n df['lower_loan_requirement'] = df['loan_percent_calc'] < 20\n return df\n\ndef define_higher_loan_requirement(df):\n df['higher_loan_requirement'] = df['loan_percent_calc'] > 40\n return df\n\ndef define_long_employement(df):\n df['long_working'] = df['person_emp_length'] > 10\n return df\n\ndef impute_empty_to_wrong_age(df):\n\n filter_con = df[\"person_age\"] > 85\n df.loc[filter_con, 'person_age'] = np.nan\n return df\n\ndef impute_empty_to_wrong_employee_len(df):\n\n filter_con = df[\"person_emp_length\"] > 60\n df.loc[filter_con, 'person_emp_length'] = np.nan\n return df\n\ndef add_features(df):\n df = impute_empty_to_wrong_age(df)\n df = impute_empty_to_wrong_employee_len(df)\n df = impute_higher_salary(df)\n df = define_home_owner(df)\n df = define_loan_percentage(df)\n df = define_lower_loan_requirement(df)\n df = define_higher_loan_requirement(df)\n df = define_long_employement(df)\n return df"
    },
    {
      "execution_count": 9,
      "code_cell_id": 67,
      "code": "feature_engieered = (\"FeatureEngineering_add_features\", DataframeFunctionTransformer(add_features))"
    },
    {
      "execution_count": 10,
      "code_cell_id": 135,
      "code": "%%time\n\nfrom sklearn.ensemble import AdaBoostRegressor\nml_support_obj = ml_support()\nbest_decision_tree_model = RandomForestClassifier(random_state = 42,n_estimators=1200,\n min_samples_split=5, min_samples_leaf = 1,\n max_features = 'auto', max_depth = None,\n bootstrap =True\n )\nregression_model = AdaBoostRegressor()\nct = ml_support_obj.get_column_transformer(False, \"\", True)\nX_train, X_test , y_train, y_test = ml_support_obj.get_train_test_data()\nfinalized_pipeline = ml_support_obj.get_final_pipeline(regression_model,ct,feature_engieered)"
    },
    {
      "execution_count": 11,
      "code_cell_id": 137,
      "code": "%%time\npreds = ml_support_obj.predit_with_pipeline(finalized_pipeline,X_train,X_test,y_train)"
    }
  ],
  "target": {
    "code_cell_id": 138,
    "code": "print(\"Balenced Accuracy Score : {0}\".format(balanced_accuracy_score(y_test, preds)))"
  }
}