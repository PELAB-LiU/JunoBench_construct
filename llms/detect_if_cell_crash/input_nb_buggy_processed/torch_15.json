{
  "executed": [
    {
      "execution_count": 1,
      "code_cell_id": 0,
      "code": "import numpy as np\nimport pandas as pd\n\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport json\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n for filename in filenames:\n print(os.path.join(dirname, filename))"
    },
    {
      "execution_count": 2,
      "code_cell_id": 1,
      "code": "jsdf = pd.read_json('data/train_annotations')\njsdf.head()"
    },
    {
      "execution_count": 3,
      "code_cell_id": 2,
      "code": "Id = []\n\nimport os\nfor dirname, _, filenames in os.walk('data/train/train'):\n for filename in filenames:\n Id.append(os.path.join(dirname, filename))\nId[:5]"
    },
    {
      "execution_count": 4,
      "code_cell_id": 3,
      "code": "train = pd.DataFrame()\ntrain = train.assign(filename = Id)\ntrain['image_id'] = train['filename'].str.replace('data/train/train/image_id_','')\ntrain['image_id'] = train['image_id'].str.replace('.jpg','')\ntrain['image_id'] = train['image_id'].astype(int)\ntrain.head()"
    },
    {
      "execution_count": 5,
      "code_cell_id": 4,
      "code": "train_data = pd.merge(train,jsdf,on='image_id',how='outer')\ntrain_data = train_data[['filename','category_id']]\ntrain_data.columns = ['filename','label']\ntrain_data.head()"
    },
    {
      "execution_count": 6,
      "code_cell_id": 5,
      "code": "train_data['filename'] = train_data['filename'].str.replace('data/train/train/','')"
    },
    {
      "execution_count": 7,
      "code_cell_id": 6,
      "code": "train_data.head()"
    },
    {
      "execution_count": 8,
      "code_cell_id": 7,
      "code": "train_data['label'] = train_data['label'].replace({1:0,2:1})"
    },
    {
      "execution_count": 9,
      "code_cell_id": 8,
      "code": "train_data.head()"
    },
    {
      "execution_count": 10,
      "code_cell_id": 9,
      "code": "train_data.nunique()"
    },
    {
      "execution_count": 11,
      "code_cell_id": 12,
      "code": "transform = transforms.Compose([\n transforms.CenterCrop((512, 512)),\n transforms.ToTensor(),\n transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])"
    },
    {
      "execution_count": 12,
      "code_cell_id": 13,
      "code": "data_path = 'data/train/train'\nimages = []\ntargets = []\n\nfor i,annotation in train_data.iterrows():\n image_name = annotation['filename']\n target = annotation['label']\n image_path = os.path.join(data_path, image_name)\n image = Image.open(image_path).convert(\"RGB\")\n image = transform(image)\n images.append(image)\n targets.append(torch.tensor(target))"
    },
    {
      "execution_count": 13,
      "code_cell_id": 14,
      "code": "image_tensor = torch.stack(images)\ntarget_tensor = torch.stack(targets)"
    },
    {
      "execution_count": 14,
      "code_cell_id": 15,
      "code": "dataset = torch.utils.data.TensorDataset(image_tensor, target_tensor)"
    },
    {
      "execution_count": 15,
      "code_cell_id": 16,
      "code": "from torch.utils.data import random_split\ntrain_dataset, test_dataset = random_split(dataset, [400, 100])"
    },
    {
      "execution_count": 16,
      "code_cell_id": 17,
      "code": "train_loader = DataLoader(train_dataset,batch_size=32,shuffle=True)\ntest_loader = DataLoader(test_dataset,batch_size=32,shuffle=True)"
    },
    {
      "execution_count": 17,
      "code_cell_id": 25,
      "code": "class CNN(nn.Module):\n def __init__(self):\n super().__init__()\n\n self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n\n self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n self.max_pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n self.fc1 = nn.Linear(32 * 128 * 128, 128)\n self.fc2 = nn.Linear(128, 1)\n\n self.relu = nn.ReLU()\n self.softmax = nn.Sigmoid()\n\n def forward(self, x):\n x = self.conv1(x)\n x = self.relu(x)\n x = self.max_pool1(x)\n\n x = self.conv2(x)\n x = self.relu(x)\n x = self.max_pool2(x)\n x = x.view(-1, 32 * 128 * 128)\n\n x = self.fc1(x)\n x = self.relu(x)\n x = self.fc2(x)\n x = self.softmax(x)\n\n return x\n\nmodel = CNN()\nloss_fn = nn.BCELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
    },
    {
      "execution_count": 18,
      "code_cell_id": 26,
      "code": "def test_model(model):\n model.eval()\n correct = 0\n total = 0\n\n device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n with torch.no_grad():\n for inputs, labels in test_loader:\n inputs, labels = inputs.to(device), labels.to(device)\n outputs = model(inputs)\n _, predicted = torch.max(outputs, 1)\n total += labels.size(0)\n correct += (predicted == labels).sum().item()\n\n accuracy = 100 * correct / total\n print(f'Accuracy on the test data: {accuracy:.2f}%')\n\ntest_model(model)"
    },
    {
      "execution_count": 19,
      "code_cell_id": 27,
      "code": "len(train_loader)"
    }
  ],
  "target": {
    "code_cell_id": 28,
    "code": "n_epoch = 1\nfor epoch in range(n_epoch):\n model.train()\n\n for batch_idx, (sekil, netice) in enumerate(train_loader):\n\n optimizer.zero_grad()\n\n outputs = model(sekil)\n loss = loss_fn(outputs, netice)\n\n loss.backward()\n optimizer.step()\n\n if (batch_idx + 1) % 4 == 0:\n print(f\"Epoch [{epoch+1}/{n_epoch}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item()}\")"
  }
}