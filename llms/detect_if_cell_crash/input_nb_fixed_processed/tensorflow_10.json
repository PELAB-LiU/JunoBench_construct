{
  "executed": [
    {
      "execution_count": 1,
      "code_cell_id": 0,
      "code": "import tensorflow as tf\nfrom transformers import TFAutoModel"
    },
    {
      "execution_count": 3,
      "code_cell_id": 1,
      "code": "import pandas as pd\nimport json\ndf_psytar = pd.read_csv(\"data/PsyTAR.csv\")\ndf_psytar.head(5)"
    },
    {
      "execution_count": 4,
      "code_cell_id": 4,
      "code": "df=df_psytar"
    },
    {
      "execution_count": 5,
      "code_cell_id": 5,
      "code": "df.head(5)"
    },
    {
      "execution_count": 6,
      "code_cell_id": 6,
      "code": "df_1 = df[df['ADR']==1]\ndf_0 = df[df['ADR']==0]"
    },
    {
      "execution_count": 7,
      "code_cell_id": 7,
      "code": "df_0 = df_0.sample(df_1.shape[0])"
    },
    {
      "execution_count": 8,
      "code_cell_id": 8,
      "code": "df = pd.concat([df_1,df_0])"
    },
    {
      "execution_count": 9,
      "code_cell_id": 9,
      "code": "from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
    },
    {
      "execution_count": 10,
      "code_cell_id": 10,
      "code": "def process_data(row):\n\n text = row['sentences']\n text = str(text)\n text = ' '.join(text.split())\n\n encodings = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n\n label = 0\n if row['ADR'] == 1:\n label += 1\n\n encodings['label'] = label\n encodings['text'] = text\n\n return encodings"
    },
    {
      "execution_count": 11,
      "code_cell_id": 11,
      "code": "print(process_data({\n 'sentences': 'this is a sample review of a movie.',\n 'ADR': 1\n}))"
    },
    {
      "execution_count": 12,
      "code_cell_id": 12,
      "code": "processed_data = []\n\nfor i in range(len(df[:1000])):\n processed_data.append(process_data(df.iloc[i]))"
    },
    {
      "execution_count": 13,
      "code_cell_id": 13,
      "code": "train_data = df[\"sentences\"]\ntrain_labels = df['ADR']"
    },
    {
      "execution_count": 15,
      "code_cell_id": 15,
      "code": "import pyarrow as pa\nfrom datasets import Dataset\n\ntrain_hg = Dataset(pa.Table.from_pandas(train_df))\nvalid_hg = Dataset(pa.Table.from_pandas(valid_df))"
    },
    {
      "execution_count": 27,
      "code_cell_id": 16,
      "code": "class HuggingFaceLayer(tf.keras.layers.Layer):\n def __init__(self, model_name, output_hidden_states=False, trainable=False, **kwargs):\n super(HuggingFaceLayer, self).__init__(**kwargs)\n self.model = TFAutoModel.from_pretrained(model_name, output_hidden_states=output_hidden_states)\n self.trainable = trainable\n\n def build(self, input_shape):\n self.model.built = True\n if not self.trainable:\n self.model.trainable = False\n super(HuggingFaceLayer, self).build(input_shape)\n\n def call(self, inputs, **kwargs):\n outputs = self.model(inputs, **kwargs)\n\n return outputs.last_hidden_state[:, 0, :]"
    },
    {
      "execution_count": 28,
      "code_cell_id": 17,
      "code": ""
    },
    {
      "execution_count": 30,
      "code_cell_id": 18,
      "code": "model_name = 'bert-base-uncased'\n\ninput_ids = tf.keras.Input(shape=(128,), dtype=tf.int32, name='input_ids')\nattention_mask = tf.keras.Input(shape=(128,), dtype=tf.int32, name='attention_mask')\n\ncls_output = HuggingFaceLayer(model_name)(inputs={'input_ids': input_ids, 'attention_mask': attention_mask})\n\noutput = tf.keras.layers.Dense(1, activation='sigmoid')(cls_output)\n\nmodel = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)"
    }
  ],
  "target": {
    "code_cell_id": 19,
    "code": "import numpy as np\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel.fit(\n x={'input_ids': np.array(train_hg['input_ids']), 'attention_mask': np.array(train_hg['attention_mask'])},\n y=np.array(train_hg['label']),\n epochs=2,\n batch_size=32\n)"
  }
}