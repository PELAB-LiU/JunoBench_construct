{
  "executed": [
    {
      "execution_count": 1,
      "code_cell_id": 0,
      "code": "\"\"\"Required Liberaries\"\"\"\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy.random import randint\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.initializers import RandomNormal\nfrom keras.models import Model\nfrom keras.layers import Conv2D , Input\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Activation\nfrom keras.layers import Concatenate\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization\nfrom matplotlib import pyplot as plt\nfrom tensorflow.keras.utils import plot_model"
    },
    {
      "execution_count": 2,
      "code_cell_id": 1,
      "code": "def define_discriminator(image_shape):\n\n init = RandomNormal(stddev=0.02)\n\n in_src_image = Input(shape=image_shape)\n\n in_target_image = Input(shape=image_shape)\n\n merged = Concatenate()([in_src_image, in_target_image])\n\n d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n d = LeakyReLU(alpha=0.2)(d)\n\n d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n d = BatchNormalization()(d)\n d = LeakyReLU(alpha=0.2)(d)\n\n d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n d = BatchNormalization()(d)\n d = LeakyReLU(alpha=0.2)(d)\n\n d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n d = BatchNormalization()(d)\n d = LeakyReLU(alpha=0.2)(d)\n\n d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n d = BatchNormalization()(d)\n d = LeakyReLU(alpha=0.2)(d)\n\n d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n patch_out = Activation('sigmoid')(d)\n\n model = Model([in_src_image, in_target_image], patch_out)\n\n opt = Adam(0.0002, beta_1=0.5)\n model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n return model"
    },
    {
      "execution_count": 3,
      "code_cell_id": 2,
      "code": "test_dis = define_discriminator((256 , 256 ,3))\ntest_dis.summary()"
    },
    {
      "execution_count": 4,
      "code_cell_id": 3,
      "code": "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n\n init = RandomNormal(stddev=0.02)\n\n g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n\n if batchnorm:\n g = BatchNormalization()(g, training=True)\n\n g = LeakyReLU(alpha=0.2)(g)\n return g\n\ndef decoder_block(layer_in, skip_in, n_filters, dropout=True):\n\n init = RandomNormal(stddev=0.02)\n\n g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n\n g = BatchNormalization()(g, training=True)\n\n if dropout:\n g = Dropout(0.5)(g, training=True)\n\n g = Concatenate()([g, skip_in])\n\n g = Activation('relu')(g)\n return g"
    },
    {
      "execution_count": 5,
      "code_cell_id": 4,
      "code": "def decoder_block(layer_in , skip_in , n_filter , dropout = True):\n init = RandomNormal(stddev = 0.02)\n g = Conv2DTranspose(n_filter , (4,4) , strides = (2,2) , padding = \"same\" , kernel_initializer=init)(layer_in)\n g = BatchNormalization()(g , training = True)\n if dropout:\n g = Dropout(0.5)(g , training = True)\n g = Concatenate()([g , skip_in])\n g = Activation(\"relu\")(g)\n return g"
    },
    {
      "execution_count": 6,
      "code_cell_id": 5,
      "code": "def define_generator(image_shape=(256,256,3)):\n\n init = RandomNormal(stddev=0.02)\n\n in_image = Input(shape=image_shape)\n\n e1 = define_encoder_block(in_image, 64, batchnorm=False)\n e2 = define_encoder_block(e1, 128)\n e3 = define_encoder_block(e2, 256)\n e4 = define_encoder_block(e3, 512)\n e5 = define_encoder_block(e4, 512)\n e6 = define_encoder_block(e5, 512)\n e7 = define_encoder_block(e6, 512)\n\n b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n b = Activation('relu')(b)\n\n d1 = decoder_block(b, e7, 512)\n d2 = decoder_block(d1, e6, 512)\n d3 = decoder_block(d2, e5, 512)\n d4 = decoder_block(d3, e4, 512, dropout=False)\n d5 = decoder_block(d4, e3, 256, dropout=False)\n d6 = decoder_block(d5, e2, 128, dropout=False)\n d7 = decoder_block(d6, e1, 64, dropout=False)\n\n g = Conv2DTranspose(image_shape[2], (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n out_image = Activation('tanh')(g)\n\n model = Model(in_image, out_image)\n return model"
    },
    {
      "execution_count": 7,
      "code_cell_id": 6,
      "code": "test_gen = define_generator((256 ,256 , 3))\ntest_gen.summary()"
    },
    {
      "execution_count": 8,
      "code_cell_id": 7,
      "code": "def define_gan(g_model, d_model, image_shape):\n\n for layer in d_model.layers:\n if not isinstance(layer, BatchNormalization):\n layer.trainable = False\n\n in_src = Input(shape=image_shape)\n\n gen_out = g_model(in_src)\n\n dis_out = d_model([in_src, gen_out])\n\n model = Model(in_src, [dis_out, gen_out])\n\n opt = Adam(lr=0.0002, beta_1=0.5)\n\n model.compile(loss=['binary_crossentropy', 'mae'],\n optimizer=opt, loss_weights=[1,100])\n return model"
    },
    {
      "execution_count": 9,
      "code_cell_id": 8,
      "code": "def generate_real_samples(dataset, n_samples, patch_shape):\n\n trainA, trainB = dataset\n\n ix = randint(0, trainA.shape[0], n_samples)\n\n X1, X2 = trainA[ix], trainB[ix]\n\n y = ones((n_samples, patch_shape, patch_shape, 1))\n return [X1, X2], y\n\ndef generate_fake_samples(g_model, samples, patch_shape):\n\n X = g_model.predict(samples)\n\n y = zeros((len(X), patch_shape, patch_shape, 1))\n return X, y\n\ndef summarize_performance(step, g_model, dataset, n_samples=3):\n\n [X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)\n\n X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n\n X_realA = (X_realA + 1) / 2.0\n X_realB = (X_realB + 1) / 2.0\n X_fakeB = (X_fakeB + 1) / 2.0\n\n for i in range(n_samples):\n plt.subplot(3, n_samples, 1 + i)\n plt.axis('off')\n plt.imshow(X_realA[i])\n\n for i in range(n_samples):\n plt.subplot(3, n_samples, 1 + n_samples + i)\n plt.axis('off')\n plt.imshow(X_fakeB[i])\n\n for i in range(n_samples):\n plt.subplot(3, n_samples, 1 + n_samples*2 + i)\n plt.axis('off')\n plt.imshow(X_realB[i])\n\n filename1 = 'plot_%06d.png' % (step+1)\n plt.savefig(filename1)\n plt.close()\n\n filename2 = 'model_%06d.h5' % (step+1)\n g_model.save(filename2)\n print('>Saved: %s and %s' % (filename1, filename2))"
    },
    {
      "execution_count": 10,
      "code_cell_id": 9,
      "code": "def train(d_model, g_model, gan_model, dataset, n_epochs=100, n_batch=1):\n n_patch = d_model.output_shape[1]\n trainA, trainB = dataset\n bat_per_epo = int(len(trainA) / n_batch)\n n_steps = bat_per_epo * n_epochs\n for i in range(n_steps):\n [X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n print('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n if (i+1) % (bat_per_epo * 10) == 0:\n summarize_performance(i, g_model, dataset)"
    },
    {
      "execution_count": 11,
      "code_cell_id": 11,
      "code": "from tensorflow.keras.utils import normalize\nimport os\nimport glob\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot\n\nSIZE_X = 256\nSIZE_Y = 256\n\ntar_images = []\n\nfor directory_path in glob.glob(\"data_small//tar_images/\"):\n for img_path in sorted(glob.glob(os.path.join(directory_path, \"*.jpg\"))):\n img = cv2.imread(img_path, 1)\n img = cv2.resize(img, (SIZE_Y, SIZE_X))\n tar_images.append(img)\ntar_images = np.array(tar_images)"
    },
    {
      "execution_count": 12,
      "code_cell_id": 12,
      "code": "from sklearn.utils import resample\ntar_image = resample(tar_images ,\n replace = False ,\n n_samples = 50,\n random_state=42)"
    },
    {
      "execution_count": 13,
      "code_cell_id": 13,
      "code": "tar_image.shape"
    }
  ],
  "target": {
    "code_cell_id": 17,
    "code": "import numpy as np\nimport cv2\nrandom_img = np.random.randint(0 , len(src_images))\nfig = plt.figure(figsize = (16, 16))\nsrc_img = np.reshape(src_images[random_img] , (256 , 256 ,3))\n\ntar_img = np.reshape(tar_images[random_img] , (256 , 256 ,3))\nplt.subplot(121)\nplt.imshow(cv2.cvtColor(src_img , cv2.COLOR_BGR2RGB))\nplt.subplot(122)\nplt.imshow(cv2.cvtColor(tar_img , cv2.COLOR_BGR2RGB))\nplt.show()"
  }
}