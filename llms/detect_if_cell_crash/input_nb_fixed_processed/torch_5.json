{
  "executed": [
    {
      "execution_count": 1,
      "code_cell_id": 0,
      "code": "import os, time\nimport numpy as np\nimport random\nrandom.seed(42)\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report\n\nimport torch\ntorch.manual_seed(42)\nfrom torch import nn\nfrom torch.optim import SGD, Adam\nfrom torch.utils.data import DataLoader, RandomSampler\nfrom torch.utils.data.dataset import Dataset\nfrom torchvision.models import resnet\nfrom torchvision import transforms, datasets, models\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torch.nn.functional as F"
    },
    {
      "execution_count": 2,
      "code_cell_id": 1,
      "code": "def load_transform_images(images_path, presplit, train_split, test_split, val_split, batch_size, threads, mean, std):\n train_transform = transforms.Compose([\n\n transforms.Resize((224,224)),\n transforms.RandomHorizontalFlip(),\n transforms.ToTensor(),\n transforms.Normalize(torch.Tensor(mean),\n torch.Tensor(std))])\n\n test_transform = transforms.Compose([\n transforms.Resize((224,224)),\n\n transforms.ToTensor(),\n transforms.Normalize(torch.Tensor(mean),\n torch.Tensor(std))])\n\n val_transform = transforms.Compose([\n transforms.Resize((224,224)),\n\n transforms.ToTensor(),\n transforms.Normalize(torch.Tensor(mean),\n torch.Tensor(std))])\n if presplit:\n try:\n training_set = datasets.ImageFolder(root=images_path+'/train', transform=train_transform)\n validation_set = datasets.ImageFolder(root=images_path+'/val', transform=val_transform)\n except FileNotFoundError:\n raise Exception('Not presplit into Training and Validation sets')\n try:\n testing_set = datasets.ImageFolder(root=images_path+'/test', transform=test_transform)\n except:\n testing_set = validation_set\n dataset = training_set\n else:\n dataset = datasets.ImageFolder(root=images_path, transform=train_transform)\n train_size = int(train_split * len(dataset))\n test_size = int(test_split * len(dataset))\n val_size = len(dataset) - train_size - test_size\n training_set, testing_set, validation_set = torch.utils.data.random_split(dataset, [train_size, test_size, val_size])\n\n training_set_loader = DataLoader(training_set, batch_size=batch_size, num_workers=threads, shuffle=True)\n validation_set_loader = DataLoader(validation_set, batch_size=batch_size, num_workers=threads, shuffle=True)\n testing_set_loader = DataLoader(testing_set, batch_size=batch_size, num_workers=threads, shuffle=False)\n\n return training_set_loader, testing_set_loader, validation_set_loader, dataset, training_set, testing_set, validation_set\n\nimages_path = 'data_small/images/Images/'\nresults_path = images_path+'_results'\npresplit = False\ntrain_split = 0.5\nval_split = 0.25\ntest_split = 0.25\nbatch_size = 128\nthreads = 0\nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\ntraining_set_loader, testing_set_loader, validation_set_loader, dataset, training_set, testing_set, validation_set = load_transform_images(images_path, presplit, train_split, test_split, val_split, batch_size, threads, mean, std)\n\nclass_names = dataset.classes\nclass_names = [classes[10:] for classes in class_names]\nclasses = ('Chihuahua', 'Japanese_spaniel', 'Maltese_dog', 'Pekinese', 'Shih-Tzu', 'Blenheim_spaniel', 'papillon', 'toy_terrier', 'Rhodesian_ridgeback', 'Afghan_hound', 'basset', 'beagle', 'bloodhound', 'bluetick', 'black-and-tan_coonhound', 'Walker_hound', 'English_foxhound', 'redbone', 'borzoi', 'Irish_wolfhound', 'Italian_greyhound', 'whippet', 'Ibizan_hound', 'Norwegian_elkhound', 'otterhound', 'Saluki', 'Scottish_deerhound', 'Weimaraner', 'Staffordshire_bullterrier', 'American_Staffordshire_terrier', 'Bedlington_terrier', 'Border_terrier', 'Kerry_blue_terrier', 'Irish_terrier', 'Norfolk_terrier', 'Norwich_terrier', 'Yorkshire_terrier', 'wire-haired_fox_terrier', 'Lakeland_terrier', 'Sealyham_terrier', 'Airedale', 'cairn', 'Australian_terrier', 'Dandie_Dinmont', 'Boston_bull', 'miniature_schnauzer', 'giant_schnauzer', 'standard_schnauzer', 'Scotch_terrier', 'Tibetan_terrier', 'silky_terrier', 'soft-coated_wheaten_terrier', 'West_Highland_white_terrier', 'Lhasa', 'flat-coated_retriever', 'curly-coated_retriever', 'golden_retriever', 'Labrador_retriever', 'Chesapeake_Bay_retriever', 'German_short-haired_pointer', 'vizsla', 'English_setter', 'Irish_setter', 'Gordon_setter', 'Brittany_spaniel', 'clumber', 'English_springer', 'Welsh_springer_spaniel', 'cocker_spaniel', 'Sussex_spaniel', 'Irish_water_spaniel', 'kuvasz', 'schipperke', 'groenendael', 'malinois', 'briard', 'kelpie', 'komondor', 'Old_English_sheepdog', 'Shetland_sheepdog', 'collie', 'Border_collie', 'Bouvier_des_Flandres', 'Rottweiler', 'German_shepherd', 'Doberman', 'miniature_pinscher', 'Greater_Swiss_Mountain_dog', 'Bernese_mountain_dog', 'Appenzeller', 'EntleBucher', 'boxer', 'bull_mastiff', 'Tibetan_mastiff', 'French_bulldog', 'Great_Dane', 'Saint_Bernard', 'Eskimo_dog', 'malamute', 'Siberian_husky', 'affenpinscher', 'basenji', 'pug', 'Leonberg', 'Newfoundland', 'Great_Pyrenees', 'Samoyed', 'Pomeranian', 'chow', 'keeshond', 'Brabancon_griffon', 'Pembroke', 'Cardigan', 'toy_poodle', 'miniature_poodle', 'standard_poodle', 'Mexican_hairless', 'dingo', 'dhole', 'African_hunting_dog')\nprint(class_names)"
    },
    {
      "execution_count": 28,
      "code_cell_id": 2,
      "code": "import torch\nimport torch.nn as nn\nimport torchvision\nimport torch.nn.functional as F\n\nclass Network(nn.Module):\n def __init__(self):\n super(Network, self).__init__()\n\n self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5, stride=1, padding=1)\n self.bn1 = nn.BatchNorm2d(12)\n self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=5, stride=1, padding=1)\n self.bn2 = nn.BatchNorm2d(12)\n self.pool = nn.MaxPool2d(2,2)\n self.conv4 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5, stride=1, padding=1)\n self.bn4 = nn.BatchNorm2d(24)\n self.conv5 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=5, stride=1, padding=1)\n self.bn5 = nn.BatchNorm2d(24)\n\n with torch.no_grad():\n dummy_input = torch.zeros(1, 3, 224, 224)\n dummy_output = self._forward_conv(dummy_input)\n self.flattened_size = dummy_output.view(1, -1).size(1)\n\n self.fc1 = nn.Linear(self.flattened_size, 120)\n\n def _forward_conv(self, input):\n x = F.relu(self.bn1(self.conv1(input)))\n x = F.relu(self.bn2(self.conv2(x)))\n x = self.pool(x)\n x = F.relu(self.bn4(self.conv4(x)))\n x = F.relu(self.bn5(self.conv5(x)))\n return x\n\n def forward(self, input):\n\n output = self._forward_conv(input)\n output = torch.flatten(output, 1)\n\n output = self.fc1(output)\n\n return output\n\nmodel = Network()"
    },
    {
      "execution_count": 29,
      "code_cell_id": 3,
      "code": "from torch.optim import Adam\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
    },
    {
      "execution_count": 33,
      "code_cell_id": 4,
      "code": "from torch.autograd import Variable\n\ndef saveModel():\n path = \"data_small/myFirstModel.pth\"\n torch.save(model.state_dict(), path)\n\ndef testAccuracy():\n\n model.eval()\n accuracy = 0.0\n total = 0.0\n\n with torch.no_grad():\n\n for data in testing_set_loader:\n\n images, labels = data\n\n outputs = model(images)\n\n _, predicted = torch.max(outputs.data, 1)\n total += labels.size(0)\n accuracy += (predicted == labels).sum().item()\n\n accuracy = (100 * accuracy / total)\n return(accuracy)\n\ndef train(num_epochs):\n\n best_accuracy = 0.0\n\n device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n print(\"The model will be running on\", device, \"device\")\n\n model.to(device)\n\n for epoch in range(num_epochs):\n running_loss = 0.0\n running_acc = 0.0\n\n for i, (images, classes) in enumerate(training_set_loader, 0):\n\n outputs = model(images.to(device))\n loss = loss_fn(outputs, classes.to(device))\n\n loss.backward()\n\n optimizer.step()\n\n running_loss += loss.item()\n if i % 1000 == 999:\n\n print('[%d, %5d] loss: %.3f' %\n (epoch + 1, i + 1, running_loss / 1000))\n\n running_loss = 0.0\n\n accuracy = testAccuracy()\n print('For epoch', epoch+1,'the test accuracy over the whole test set is %d %%' % (accuracy))\n\n if accuracy > best_accuracy:\n saveModel()\n best_accuracy = accuracy"
    },
    {
      "execution_count": 34,
      "code_cell_id": 5,
      "code": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef imageshow(img):\n img = img / 2 + 0.5\n npimg = img.numpy()\n plt.imshow(np.transpose(npimg, (1, 2, 0)))\n plt.show()\n\ndef testBatch():\n\n images, labels = next(iter(testing_set_loader))\n\n imageshow(torchvision.utils.make_grid(images))\n\n print('Real labels: ', ' '.join('%5s' % classes[labels[j]]\n for j in range(batch_size)))\n\n outputs = model(images)\n\n _, predicted = torch.max(outputs, 1)\n\n print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n for j in range(batch_size)))"
    }
  ],
  "target": {
    "code_cell_id": 6,
    "code": "if __name__ == \"__main__\":\n\n train(2)\n print('Finished Training')\n\n testAccuracy()\n\n model = Network()\n path = \"data_small/myFirstModel.pth\"\n model.load_state_dict(torch.load(path))\n\n testBatch()"
  }
}