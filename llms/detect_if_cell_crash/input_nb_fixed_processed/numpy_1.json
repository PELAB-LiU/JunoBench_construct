{
  "executed": [
    {
      "execution_count": 1,
      "code_cell_id": 0,
      "code": "import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as transforms\nimport torchvision\nimport os"
    },
    {
      "execution_count": 2,
      "code_cell_id": 1,
      "code": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nbatch_size = 32\nimg_size = 64\nnum_epochs = 2\nlearning_rate = 3e-4\nnum_channels = 3\nz_dim = 100"
    },
    {
      "execution_count": 3,
      "code_cell_id": 2,
      "code": "transformer = transforms.Compose([\n transforms.Resize(64),\n transforms.ToTensor(),\n transforms.Normalize(mean = [0.5 for _ in range(num_channels)], std = [0.5 for _ in range(num_channels)])\n])"
    },
    {
      "execution_count": 7,
      "code_cell_id": 3,
      "code": "dataset = ImageFolder(root = \"data_small/celeba_hq_256\",\n transform = transformer)"
    },
    {
      "execution_count": 8,
      "code_cell_id": 4,
      "code": "train_dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = True)\ntrain_dataloader"
    },
    {
      "execution_count": 9,
      "code_cell_id": 5,
      "code": "train_features_batch, train_labels_batch = next(iter(train_dataloader))\ntrain_features_batch.shape, train_labels_batch.shape"
    },
    {
      "execution_count": 10,
      "code_cell_id": 6,
      "code": "def initialize_weights(model):\n\n for m in model.modules():\n if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n nn.init.normal_(m.weight.data, 0.0, 0.02)"
    },
    {
      "execution_count": 11,
      "code_cell_id": 7,
      "code": "class Generator(nn.Module):\n def __init__(self, z_dim, num_channels):\n super(Generator,self).__init__()\n self.gen = nn.Sequential(\n self._block(z_dim,1024,1,0,4),\n self._block(1024, 512,2,0,2),\n self._block(512, 256,2,0,2),\n self._block(256, 128,2,0,2),\n nn.ConvTranspose2d(in_channels = 128,\n out_channels = num_channels,\n stride = 2,\n kernel_size = 2,\n padding = 0),\n nn.Tanh()\n )\n def _block(self,in_channels, out_channels, stride, padding, kernel_size):\n block = nn.Sequential(\n nn.ConvTranspose2d(in_channels = in_channels,\n out_channels = out_channels,\n kernel_size = kernel_size,\n stride = stride,\n padding = padding,\n bias = False),\n nn.LeakyReLU(0.2)\n )\n return block\n\n def forward(self,x):\n return self.gen(x)\n\nclass Dis(nn.Module):\n def __init__(self,num_channels):\n super(Dis,self).__init__()\n self.dis = nn.Sequential(\n self._block(num_channels, 64,2,1,4),\n self._block(64, 128,2,0,2),\n self._block(128,256 ,2,0,2),\n self._block(256,512 ,2,0,2),\n nn.Conv2d(64 * 8, 1, kernel_size=4, stride=2, padding=0),\n nn.Sigmoid(),\n )\n pass\n def _block(self,in_channels, out_channels, stride, padding, kernel_size):\n block = nn.Sequential(\n nn.Conv2d(in_channels = in_channels,\n out_channels = out_channels,\n stride = stride,\n padding = padding,\n kernel_size=kernel_size,\n bias = False),\n\n nn.LeakyReLU(0.2)\n )\n return block\n\n def forward(self,x):\n return self.dis(x)\n\ngen = Generator(100,3).to(device)\ndisc = Dis(3).to(device)"
    },
    {
      "execution_count": 12,
      "code_cell_id": 8,
      "code": "def test():\n N, in_channels, H, W = 8, 3, 64, 64\n noise_dim = 100\n x = torch.randn((N, in_channels, H, W))\n disc = Dis(in_channels)\n assert disc(x).shape == (N, 1, 1, 1), \"Discriminator test failed\"\n gen = Generator(noise_dim, in_channels)\n z = torch.randn((N, noise_dim, 1, 1))\n assert gen(z).shape == (N, in_channels, H, W), \"Generator test failed\"\n print(\"Success, tests passed!\")\ntest()"
    },
    {
      "execution_count": 13,
      "code_cell_id": 9,
      "code": "from torch.utils.tensorboard import SummaryWriter\nimport torch.optim as optim\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nLEARNING_RATE = 2e-4\nBATCH_SIZE = 128\nIMAGE_SIZE = 64\nCHANNELS_IMG = 1\nNOISE_DIM = 100\nNUM_EPOCHS = 2\nFEATURES_DISC = 64\nFEATURES_GEN = 64\n\ninitialize_weights(gen)\ninitialize_weights(disc)\nopt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\nopt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\ncriterion = nn.BCELoss()\n\nfixed_noise = torch.randn(32, NOISE_DIM, 1, 1).to(device)\nwriter_real = SummaryWriter(f\"logs/real\")\nwriter_fake = SummaryWriter(f\"logs/fake\")\nstep = 0\ngen.train()\ndisc.train()\n\nfor epoch in range(NUM_EPOCHS):\n\n for batch_idx, (real, _) in enumerate(train_dataloader):\n real = real.to(device)\n noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1, 1).to(device)\n fake = gen(noise)\n\n disc_real = disc(real).reshape(-1)\n loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n disc_fake = disc(fake.detach()).reshape(-1)\n loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n loss_disc = (loss_disc_real + loss_disc_fake) / 2\n disc.zero_grad()\n loss_disc.backward()\n opt_disc.step()\n\n output = disc(fake).reshape(-1)\n loss_gen = criterion(output, torch.ones_like(output))\n gen.zero_grad()\n loss_gen.backward()\n opt_gen.step()\n\n if batch_idx % 500 == 0:\n print(\n f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(train_dataloader)} \\\n Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\"\n )\n\n with torch.no_grad():\n fake = gen(fixed_noise)\n\n img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n\n writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n\n step += 1"
    },
    {
      "execution_count": 134,
      "code_cell_id": 14,
      "code": "g = Gen(100,3,64)\nd = Discriminator(3)\nprint(summary(d, input_size=[1, 3, 64, 64]))\nsummary(g, input_size=[1, 100, 1, 1])"
    }
  ],
  "target": {
    "code_cell_id": 10,
    "code": "import matplotlib.pyplot as plt\ndef visual():\n\n n=4\n\n k=0\n z = torch.randn((16, 100, 1, 1)).to(device)\n out= gen(z)\n plt.figure(figsize=(16,16))\n out = out.cpu()\n out = out.detach().numpy()\n for i in range(n):\n for j in range(n):\n ax=plt.subplot(n,n,k+1)\n img = (out[k]+1)/2\n img = np.transpose(img,(1,2,0))\n plt.imshow(img)\n plt.axis('off')\n k+=1\nvisual()"
  }
}